{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from utils import Tau3MuDataset, Root2Df, get_data_loaders, load_checkpoint, log_epoch, Criterion, add_cuts_to_config\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from models import Model\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_id = 3\n",
    "log_name = '05_16_2022_14_54_35-GNN_full_dR_1-cut1'  # log id of the saved model to load\n",
    "setting = log_name.split('-')[1]\n",
    "cut_id = log_name.split('-')[2]\n",
    "\n",
    "config = yaml.safe_load(Path(f'./configs/{setting}.yml').open('r'))\n",
    "config = add_cuts_to_config(config, cut_id)\n",
    "device = torch.device(f'cuda:{cuda_id}' if cuda_id >= 0 else 'cpu')\n",
    "log_path = Path(config['data']['log_dir']) / log_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Splits]\n",
      "    train: 43146. # pos: 7191, # neg: 35955. Pos:Neg: 0.200\n",
      "    valid: 9240. # pos: 1540, # neg: 7700. Pos:Neg: 0.200\n",
      "    test: 457487. # pos: 1542, # neg: 455945. Pos:Neg: 0.003\n"
     ]
    }
   ],
   "source": [
    "data_loaders, x_dim, edge_attr_dim, dataset = get_data_loaders(setting, config['data'], config['optimizer']['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(dataset.get_df_save_path())\n",
    "assert len(df) == len(dataset)  # let's not consider the half detector case, where len(dataset) will be roughly doubled as each neg200 gives 2 neg samples (both endcaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading checkpoint from 05_16_2022_14_54_35-GNN_full_dR_1-cut1\n"
     ]
    }
   ],
   "source": [
    "model = Model(x_dim, edge_attr_dim, config['data']['virtual_node'], config['model']).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['optimizer']['lr'])\n",
    "load_checkpoint(model, optimizer, log_path, device)\n",
    "criterion = Criterion(config['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_one_batch(data, model, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    clf_logits = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, batch=data.batch, data=data)\n",
    "    loss, loss_dict = criterion(clf_logits.sigmoid(), data.y)\n",
    "    return loss_dict, clf_logits.data.cpu()\n",
    "\n",
    "\n",
    "def run_one_epoch(data_loader, epoch, phase, device, model, criterion):\n",
    "    loader_len = len(data_loader)\n",
    "    run_one_batch = eval_one_batch\n",
    "    phase = 'test ' if phase == 'test' else phase  # align tqdm desc bar\n",
    "\n",
    "    all_loss_dict, all_clf_logits, all_clf_labels, all_sample_idx = {}, [], [], []\n",
    "    pbar = tqdm(data_loader, total=loader_len)\n",
    "    for idx, data in enumerate(pbar):\n",
    "        loss_dict, clf_logits = run_one_batch(data.to(device), model, criterion)\n",
    "\n",
    "        desc = log_epoch(epoch, phase, loss_dict, clf_logits, data.y.data.cpu(), batch=True)\n",
    "        for k, v in loss_dict.items():\n",
    "            all_loss_dict[k] = all_loss_dict.get(k, 0) + v\n",
    "        all_clf_logits.append(clf_logits), all_clf_labels.append(data.y.data.cpu()), all_sample_idx.append(data.sample_idx.data.cpu())\n",
    "\n",
    "        if idx == loader_len - 1:\n",
    "            all_clf_logits, all_clf_labels, all_sample_idx = torch.cat(all_clf_logits), torch.cat(all_clf_labels), torch.cat(all_sample_idx)\n",
    "            for k, v in all_loss_dict.items():\n",
    "                all_loss_dict[k] = v / loader_len\n",
    "            desc, auroc, recall, avg_loss = log_epoch(epoch, phase, all_loss_dict, all_clf_logits, all_clf_labels, False, None)\n",
    "        pbar.set_description(desc)\n",
    "\n",
    "    return avg_loss, auroc, recall, all_clf_logits, all_sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 999]: train finished, focal: 0.006, total: 0.006, auroc: 0.689, recall@maxfpr: 0.006: 100%|██████████| 169/169 [00:11<00:00, 14.83it/s]\n",
      "[Epoch: 999]: valid finished, focal: 0.006, total: 0.006, auroc: 0.688, recall@maxfpr: 0.006: 100%|██████████| 37/37 [00:02<00:00, 16.69it/s]\n",
      "[Epoch: 999]: test  finished, focal: 0.003, total: 0.003, auroc: 0.693, recall@maxfpr: 0.005: 100%|██████████| 1788/1788 [01:38<00:00, 18.22it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_probs, all_sample_idx = [], []\n",
    "for phase in ['train', 'valid', 'test']:\n",
    "    avg_loss, auroc, recall, clf_logits, sample_idx = run_one_epoch(data_loaders[phase], 999, phase, device, model, criterion)\n",
    "    clf_probs.append(clf_logits.sigmoid())\n",
    "    all_sample_idx.append(sample_idx)\n",
    "clf_probs = torch.cat(clf_probs)\n",
    "all_sample_idx = torch.cat(all_sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({'sample_idx': all_sample_idx, 'probs': clf_probs.reshape(-1)})\n",
    "scores = scores.sort_values('sample_idx').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_pickle(dataset.get_df_save_path().parent / f'{setting}-scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45135e56c447e54bdb1e1c0bb84ad415b64665bf9f8fb7efb25fee4420f52c63"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tau3mu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
