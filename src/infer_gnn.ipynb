{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from utils import get_data_loaders, load_checkpoint, log_epoch, Criterion, add_cuts_to_config\n",
    "import torch\n",
    "from models import Model\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_id = 3\n",
    "log_name = '05_16_2022_17_06_28-GNN_half_dR_1'  # log id of the saved model to load\n",
    "setting = log_name.split('-')[1]\n",
    "\n",
    "config = yaml.safe_load(Path(f'./configs/{setting}.yml').open('r'))\n",
    "device = torch.device(f'cuda:{cuda_id}' if cuda_id >= 0 else 'cpu')\n",
    "log_path = Path(config['data']['log_dir']) / log_name\n",
    "\n",
    "if len(log_name.split('-')) > 2:\n",
    "    cut_id = log_name.split('-')[2]\n",
    "    config = add_cuts_to_config(config, cut_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Splits]\n",
      "    train: 332406. # pos: 55401, # neg: 277005. Pos:Neg: 0.200\n",
      "    valid: 71226. # pos: 11871, # neg: 59355. Pos:Neg: 0.200\n",
      "    test: 674713. # pos: 11873, # neg: 662840. Pos:Neg: 0.018\n"
     ]
    }
   ],
   "source": [
    "data_loaders, x_dim, edge_attr_dim, dataset = get_data_loaders(setting, config['data'], config['optimizer']['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(578745, 1078345)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(dataset.get_df_save_path())\n",
    "len(df), len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading checkpoint from 05_16_2022_17_06_28-GNN_half_dR_1\n"
     ]
    }
   ],
   "source": [
    "model = Model(x_dim, edge_attr_dim, config['data']['virtual_node'], config['model']).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['optimizer']['lr'])\n",
    "load_checkpoint(model, optimizer, log_path, device)\n",
    "criterion = Criterion(config['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_one_batch(data, model, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    clf_logits = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, batch=data.batch, data=data)\n",
    "    loss, loss_dict = criterion(clf_logits.sigmoid(), data.y)\n",
    "    return loss_dict, clf_logits.data.cpu()\n",
    "\n",
    "\n",
    "def run_one_epoch(data_loader, epoch, phase, device, model, criterion):\n",
    "    loader_len = len(data_loader)\n",
    "    run_one_batch = eval_one_batch\n",
    "    phase = 'test ' if phase == 'test' else phase  # align tqdm desc bar\n",
    "\n",
    "    all_loss_dict, all_clf_logits, all_clf_labels, all_sample_idx, all_endcap = {}, [], [], [], []\n",
    "    pbar = tqdm(data_loader, total=loader_len)\n",
    "    for idx, data in enumerate(pbar):\n",
    "        loss_dict, clf_logits = run_one_batch(data.to(device), model, criterion)\n",
    "\n",
    "        desc = log_epoch(epoch, phase, loss_dict, clf_logits, data.y.data.cpu(), batch=True)\n",
    "        for k, v in loss_dict.items():\n",
    "            all_loss_dict[k] = all_loss_dict.get(k, 0) + v\n",
    "        all_clf_logits.append(clf_logits), all_clf_labels.append(data.y.data.cpu())\n",
    "        all_sample_idx.append(data.sample_idx.data.cpu()), all_endcap.append(data.endcap.data.cpu())\n",
    "\n",
    "        if idx == loader_len - 1:\n",
    "            all_clf_logits, all_clf_labels = torch.cat(all_clf_logits), torch.cat(all_clf_labels)\n",
    "            all_sample_idx, all_endcap = torch.cat(all_sample_idx), torch.cat(all_endcap)\n",
    "            for k, v in all_loss_dict.items():\n",
    "                all_loss_dict[k] = v / loader_len\n",
    "            desc, auroc, recall, avg_loss = log_epoch(epoch, phase, all_loss_dict, all_clf_logits, all_clf_labels, False, None)\n",
    "        pbar.set_description(desc)\n",
    "\n",
    "    return avg_loss, auroc, recall, all_clf_logits, all_sample_idx, all_endcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 999]: train finished, focal: 0.006, total: 0.006, auroc: 0.659, recall@maxfpr: 0.003: 100%|██████████| 1299/1299 [01:18<00:00, 16.64it/s]\n",
      "[Epoch: 999]: valid finished, focal: 0.006, total: 0.006, auroc: 0.664, recall@maxfpr: 0.002: 100%|██████████| 279/279 [00:15<00:00, 18.12it/s]\n",
      "[Epoch: 999]: test  finished, focal: 0.005, total: 0.005, auroc: 0.664, recall@maxfpr: 0.004: 100%|██████████| 2636/2636 [02:12<00:00, 19.89it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_probs, all_sample_idx, all_endcap = [], [], []\n",
    "for phase in ['train', 'valid', 'test']:\n",
    "    avg_loss, auroc, recall, clf_logits, sample_idx, endcap = run_one_epoch(data_loaders[phase], 999, phase, device, model, criterion)\n",
    "    clf_probs.append(clf_logits.sigmoid())\n",
    "    all_sample_idx.append(sample_idx)\n",
    "    all_endcap.append(endcap)\n",
    "    \n",
    "clf_probs = torch.cat(clf_probs)\n",
    "all_sample_idx = torch.cat(all_sample_idx)\n",
    "all_endcap = torch.cat(all_endcap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({'sample_idx': all_sample_idx, 'probs': clf_probs.reshape(-1), 'endcap': all_endcap})\n",
    "scores['score_dict'] = scores.apply(lambda x: {x['endcap']: x['probs']}, axis=1)\n",
    "scores = scores.sort_values('sample_idx').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_endcap(x):\n",
    "    res = {}\n",
    "    for each in x:\n",
    "        res = res | each\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_scores = scores.groupby('sample_idx')['score_dict'].agg(agg_endcap)\n",
    "assert len(agg_scores) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_scores.to_pickle(dataset.get_df_save_path().parent / f'{setting}-scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_idx\n",
       "0                                {-1.0: 0.5348360538482666}\n",
       "1                                {-1.0: 0.4922066926956177}\n",
       "2                                 {1.0: 0.5420222282409668}\n",
       "3                                {-1.0: 0.5099743604660034}\n",
       "4                                {-1.0: 0.5291178822517395}\n",
       "                                ...                        \n",
       "578740    {-1.0: 0.41937151551246643, 1.0: 0.48859730362...\n",
       "578741    {1.0: 0.47036778926849365, -1.0: 0.50370985269...\n",
       "578742    {1.0: 0.5109522342681885, -1.0: 0.486385315656...\n",
       "578743    {-1.0: 0.5223032236099243, 1.0: 0.527758598327...\n",
       "578744    {1.0: 0.5292389392852783, -1.0: 0.486385315656...\n",
       "Name: score_dict, Length: 578745, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45135e56c447e54bdb1e1c0bb84ad415b64665bf9f8fb7efb25fee4420f52c63"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tau3mu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
