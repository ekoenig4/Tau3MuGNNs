{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from utils import get_data_loaders, load_checkpoint, log_epoch, Criterion, add_cuts_to_config\n",
    "import torch\n",
    "from models import Model\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_id = 3\n",
    "log_name = '05_16_2022_15_49_29-GNN_full_dR_1'  # log id of the saved model to load\n",
    "setting = log_name.split('-')[1]\n",
    "\n",
    "config = yaml.safe_load(Path(f'./configs/{setting}.yml').open('r'))\n",
    "device = torch.device(f'cuda:{cuda_id}' if cuda_id >= 0 else 'cpu')\n",
    "log_path = Path(config['data']['log_dir']) / log_name\n",
    "\n",
    "if len(log_name.split('-')) > 2:\n",
    "    cut_id = log_name.split('-')[2]\n",
    "    config = add_cuts_to_config(config, cut_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Splits]\n",
      "    train: 332406. # pos: 55401, # neg: 277005. Pos:Neg: 0.200\n",
      "    valid: 71226. # pos: 11871, # neg: 59355. Pos:Neg: 0.200\n",
      "    test: 175113. # pos: 11873, # neg: 163240. Pos:Neg: 0.073\n"
     ]
    }
   ],
   "source": [
    "data_loaders, x_dim, edge_attr_dim, dataset = get_data_loaders(setting, config['data'], config['optimizer']['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(dataset.get_df_save_path())\n",
    "assert len(df) == len(dataset)  # let's not consider the half detector case, where len(dataset) will be roughly doubled as each neg200 gives 2 neg samples (both endcaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading checkpoint from 05_16_2022_15_49_29-GNN_full_dR_1\n"
     ]
    }
   ],
   "source": [
    "model = Model(x_dim, edge_attr_dim, config['data']['virtual_node'], config['model']).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['optimizer']['lr'])\n",
    "load_checkpoint(model, optimizer, log_path, device)\n",
    "criterion = Criterion(config['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_one_batch(data, model, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    clf_logits = model(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, batch=data.batch, data=data)\n",
    "    loss, loss_dict = criterion(clf_logits.sigmoid(), data.y)\n",
    "    return loss_dict, clf_logits.data.cpu()\n",
    "\n",
    "\n",
    "def run_one_epoch(data_loader, epoch, phase, device, model, criterion):\n",
    "    loader_len = len(data_loader)\n",
    "    run_one_batch = eval_one_batch\n",
    "    phase = 'test ' if phase == 'test' else phase  # align tqdm desc bar\n",
    "\n",
    "    all_loss_dict, all_clf_logits, all_clf_labels, all_sample_idx = {}, [], [], []\n",
    "    pbar = tqdm(data_loader, total=loader_len)\n",
    "    for idx, data in enumerate(pbar):\n",
    "        loss_dict, clf_logits = run_one_batch(data.to(device), model, criterion)\n",
    "\n",
    "        desc = log_epoch(epoch, phase, loss_dict, clf_logits, data.y.data.cpu(), batch=True)\n",
    "        for k, v in loss_dict.items():\n",
    "            all_loss_dict[k] = all_loss_dict.get(k, 0) + v\n",
    "        all_clf_logits.append(clf_logits), all_clf_labels.append(data.y.data.cpu()), all_sample_idx.append(data.sample_idx.data.cpu())\n",
    "\n",
    "        if idx == loader_len - 1:\n",
    "            all_clf_logits, all_clf_labels, all_sample_idx = torch.cat(all_clf_logits), torch.cat(all_clf_labels), torch.cat(all_sample_idx)\n",
    "            for k, v in all_loss_dict.items():\n",
    "                all_loss_dict[k] = v / loader_len\n",
    "            desc, auroc, recall, avg_loss = log_epoch(epoch, phase, all_loss_dict, all_clf_logits, all_clf_labels, False, None)\n",
    "        pbar.set_description(desc)\n",
    "\n",
    "    return avg_loss, auroc, recall, all_clf_logits, all_sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 999]: train finished, focal: 0.006, total: 0.006, auroc: 0.636, recall@maxfpr: 0.003: 100%|██████████| 1299/1299 [01:12<00:00, 17.98it/s]\n",
      "[Epoch: 999]: valid finished, focal: 0.006, total: 0.006, auroc: 0.636, recall@maxfpr: 0.002: 100%|██████████| 279/279 [00:15<00:00, 18.30it/s]\n",
      "[Epoch: 999]: test  finished, focal: 0.005, total: 0.005, auroc: 0.639, recall@maxfpr: 0.003: 100%|██████████| 685/685 [00:38<00:00, 17.60it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_probs, all_sample_idx = [], []\n",
    "for phase in ['train', 'valid', 'test']:\n",
    "    avg_loss, auroc, recall, clf_logits, sample_idx = run_one_epoch(data_loaders[phase], 999, phase, device, model, criterion)\n",
    "    clf_probs.append(clf_logits.sigmoid())\n",
    "    all_sample_idx.append(sample_idx)\n",
    "clf_probs = torch.cat(clf_probs)\n",
    "all_sample_idx = torch.cat(all_sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({'sample_idx': all_sample_idx, 'probs': clf_probs.reshape(-1)})\n",
    "scores = scores.sort_values('sample_idx').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_pickle(dataset.get_df_save_path().parent / f'{setting}-scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_idx</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.509518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.506023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.523474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.550908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.528242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578740</th>\n",
       "      <td>578740</td>\n",
       "      <td>0.469370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578741</th>\n",
       "      <td>578741</td>\n",
       "      <td>0.470245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578742</th>\n",
       "      <td>578742</td>\n",
       "      <td>0.490662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578743</th>\n",
       "      <td>578743</td>\n",
       "      <td>0.523394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578744</th>\n",
       "      <td>578744</td>\n",
       "      <td>0.513317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578745 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_idx     probs\n",
       "0                0  0.509518\n",
       "1                1  0.506023\n",
       "2                2  0.523474\n",
       "3                3  0.550908\n",
       "4                4  0.528242\n",
       "...            ...       ...\n",
       "578740      578740  0.469370\n",
       "578741      578741  0.470245\n",
       "578742      578742  0.490662\n",
       "578743      578743  0.523394\n",
       "578744      578744  0.513317\n",
       "\n",
       "[578745 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45135e56c447e54bdb1e1c0bb84ad415b64665bf9f8fb7efb25fee4420f52c63"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tau3mu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
